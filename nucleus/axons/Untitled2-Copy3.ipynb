{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape+(1,))\n",
    "x_test = x_test.reshape(x_test.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder:\n",
    "    \"\"\"A class that can format data.\n",
    "    This class provides ways to transform data's classification label into vector.\n",
    "    Attributes:\n",
    "          data: The input data\n",
    "          n_classes: The number of classes in the classification problem.\n",
    "          labels: The number of labels.\n",
    "          label_to_vec: Mapping from label to vector.\n",
    "          int_to_label: Mapping from int to label.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize a OneHotEncoder\"\"\"\n",
    "        self.data = None\n",
    "        self.n_classes = 0\n",
    "        self.labels = None\n",
    "        self.label_to_vec = {}\n",
    "        self.int_to_label = {}\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"Create mapping from label to vector, and vector to label.\"\"\"\n",
    "        data = np.array(data).flatten()\n",
    "        self.labels = set(data)\n",
    "        self.n_classes = len(self.labels)\n",
    "        for index, label in enumerate(self.labels):\n",
    "            vec = np.array([0] * self.n_classes)\n",
    "            vec[index] = 1\n",
    "            self.label_to_vec[label] = vec\n",
    "            self.int_to_label[index] = label\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\"Get vector for every element in the data array.\"\"\"\n",
    "        data = np.array(data)\n",
    "        if len(data.shape) > 1:\n",
    "            data = data.flatten()\n",
    "        return np.array(list(map(lambda x: self.label_to_vec[x], data)))\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        \"\"\"Get label for every element in data.\"\"\"\n",
    "        return np.array(list(map(lambda x: self.int_to_label[x], np.argmax(np.array(data), axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_y(y_train):\n",
    "    # Transform y_train.\n",
    "    y_encoder = OneHotEncoder()\n",
    "    y_encoder.fit(y_train)\n",
    "    y_train = y_encoder.transform(y_train)\n",
    "    return y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = transform_y(y_test)\n",
    "y_train = transform_y(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gautham/hacks/prototype/env/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from autokeras.preprocessor import OneHotEncoder\n",
    "y_encoder = OneHotEncoder()\n",
    "y_encoder.fit(y_train)\n",
    "y_train = y_encoder.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    "val = model.predict(x_test)\n",
    "print(val[0].argmax(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5') \n",
    "\n",
    "\n",
    "# creates a HDF5 file 'my_model.h5'\n",
    "# del model  # deletes the existing model\n",
    "\n",
    "# # returns a compiled model\n",
    "# # identical to the previous one\n",
    "# model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"my_model.h5\")\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss 1:', score[0])\n",
    "print('Test accuracy 1:', score[1])\n",
    "model.fit(x_train, y_train,batch_size=100,epochs=1,verbose=0)\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss 2:', score[0])\n",
    "print('Test accuracy 2:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
